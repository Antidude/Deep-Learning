{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP-Week4-Exercise-Shakespeare-Question.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOwsuGQQY9OL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "### YOUR CODE HERE\n",
        "# Figure out how to import regularizers\n",
        "from tensorflow.keras import regularizers\n",
        "###\n",
        "import tensorflow.keras.utils as ku \n",
        "import numpy as np "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wi79tFIwdMdA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbRQzlRZgn-q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import  keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApIk7I-YfyTg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 793
        },
        "outputId": "23daf1ea-b208-4dd7-a6d1-c309e12adf8f"
      },
      "source": [
        "!pip install tensorflow==2.0.0-beta0"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.0.0-beta0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dc/cf/99e6b89e6f7adc825f417cab601aa0ba4ff8870a0488fa8a46da55ae57c0/tensorflow-2.0.0b0-cp27-cp27mu-manylinux1_x86_64.whl (87.9MB)\n",
            "\u001b[K     |████████████████████████████████| 87.9MB 1.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow==2.0.0-beta0) (1.15.0)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow==2.0.0-beta0) (2.0.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow==2.0.0-beta0) (1.0.8)\n",
            "Collecting tf-estimator-nightly<1.14.0.dev2019060502,>=1.14.0.dev2019060501 (from tensorflow==2.0.0-beta0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/dd/99c47dd007dcf10d63fd895611b063732646f23059c618a373e85019eb0e/tf_estimator_nightly-1.14.0.dev2019060501-py2.py3-none-any.whl (496kB)\n",
            "\u001b[K     |████████████████████████████████| 501kB 34.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python2.7/dist-packages (from tensorflow==2.0.0-beta0) (1.11.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python2.7/dist-packages (from tensorflow==2.0.0-beta0) (3.7.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python2.7/dist-packages (from tensorflow==2.0.0-beta0) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow==2.0.0-beta0) (0.2.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python2.7/dist-packages (from tensorflow==2.0.0-beta0) (0.33.6)\n",
            "Collecting tb-nightly<1.14.0a20190604,>=1.14.0a20190603 (from tensorflow==2.0.0-beta0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/df/f15af3319c0094c0c74ca291f10d7b1235196988ab67c11bc09950bb7b07/tb_nightly-1.14.0a20190603-py2-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 39.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python2.7/dist-packages (from tensorflow==2.0.0-beta0) (1.16.4)\n",
            "Requirement already satisfied: enum34>=1.1.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow==2.0.0-beta0) (1.1.6)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow==2.0.0-beta0) (1.12.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow==2.0.0-beta0) (0.7.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow==2.0.0-beta0) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow==2.0.0-beta0) (0.1.7)\n",
            "Requirement already satisfied: backports.weakref>=1.0rc1 in /usr/local/lib/python2.7/dist-packages (from tensorflow==2.0.0-beta0) (1.0.post1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow==2.0.0-beta0) (0.8.0)\n",
            "Requirement already satisfied: futures>=2.2.0 in /usr/local/lib/python2.7/dist-packages (from grpcio>=1.8.6->tensorflow==2.0.0-beta0) (3.2.0)\n",
            "Requirement already satisfied: funcsigs>=1; python_version < \"3.3\" in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0->tensorflow==2.0.0-beta0) (1.0.2)\n",
            "Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0->tensorflow==2.0.0-beta0) (5.4.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python2.7/dist-packages (from keras-applications>=1.0.6->tensorflow==2.0.0-beta0) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python2.7/dist-packages (from protobuf>=3.6.1->tensorflow==2.0.0-beta0) (41.2.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python2.7/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta0) (0.15.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python2.7/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta0) (3.1.1)\n",
            "Installing collected packages: tf-estimator-nightly, tb-nightly, tensorflow\n",
            "  Found existing installation: tensorflow 1.14.0\n",
            "    Uninstalling tensorflow-1.14.0:\n",
            "      Successfully uninstalled tensorflow-1.14.0\n",
            "Successfully installed tb-nightly-1.14.0a20190603 tensorflow-2.0.0b0 tf-estimator-nightly-1.14.0.dev2019060501\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorboard",
                  "tensorflow",
                  "tensorflow_estimator"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PRnDnCW-Z7qv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "ed147aa3-077f-4c50-93e7-e3e5d83bc95e"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sonnets.txt \\\n",
        "    -O /tmp/sonnets.txt\n",
        "data = open('/tmp/sonnets.txt').read()\n",
        "\n",
        "corpus = data.lower().split(\"\\n\")\n",
        "\n",
        "\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "# create input sequences using list of tokens\n",
        "input_sequences = []\n",
        "for line in corpus:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tinput_sequences.append(n_gram_sequence)\n",
        "\n",
        "\n",
        "# pad sequences \n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# create predictors and label\n",
        "predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "\n",
        "label = ku.to_categorical(label, num_classes=total_words)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-09-20 11:55:30--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sonnets.txt\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.204.128, 2404:6800:4008:c00::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.204.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 93578 (91K) [text/plain]\n",
            "Saving to: ‘/tmp/sonnets.txt’\n",
            "\n",
            "\r/tmp/sonnets.txt      0%[                    ]       0  --.-KB/s               \r/tmp/sonnets.txt    100%[===================>]  91.38K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2019-09-20 11:55:30 (55.2 MB/s) - ‘/tmp/sonnets.txt’ saved [93578/93578]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7lOOoY6XVks",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "fbd6f2c4-8008-41f4-ecce-6794fa76422e"
      },
      "source": [
        "vocab_size = 10000\n",
        "embedding_vectors = 32 "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9vH8Y59ajYL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "outputId": "88d75ee9-cda6-45cf-f2fa-fb977dfd7e0b"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(tf.keras.layers.Embedding(total_words,32, embeddings_initializer='uniform', embeddings_regularizer=None, activity_regularizer=None, embeddings_constraint=None, mask_zero=False, input_length=None))\n",
        "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(10,return_sequences=True)))\n",
        "model.add(tf.keras.layers.Dropout(0.1, noise_shape=None, seed=None))\n",
        "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(10)))\n",
        "model.add(tf.keras.layers.Dense(64,activation = \"relu\",kernel_regularizer=keras.regularizers.l1_l2(l1=0.01, l2=0.01)))\n",
        "model.add(tf.keras.layers.Dense(3211,activation = \"softmax\"))\n",
        "\n",
        "model.compile(loss = \"categorical_crossentropy\",optimizer = \"adam\",metrics = ['accuracy'])\n",
        "print(model.summary())\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_10 (Embedding)     (None, None, 32)          102752    \n",
            "_________________________________________________________________\n",
            "bidirectional_20 (Bidirectio (None, None, 20)          3440      \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, None, 20)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_21 (Bidirectio (None, 20)                2480      \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 64)                1344      \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 3211)              208715    \n",
            "=================================================================\n",
            "Total params: 318,731\n",
            "Trainable params: 318,731\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIg2f1HBxqof",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b3ee82a7-be87-44d5-89c3-186f60a81a57"
      },
      "source": [
        " history = model.fit(predictors, label, epochs=100, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 15462 samples\n",
            "Epoch 1/100\n",
            "15462/15462 [==============================] - 14s 897us/sample - loss: 7.4173 - accuracy: 0.0213\n",
            "Epoch 2/100\n",
            "15462/15462 [==============================] - 12s 779us/sample - loss: 6.5723 - accuracy: 0.0217\n",
            "Epoch 3/100\n",
            "15462/15462 [==============================] - 12s 770us/sample - loss: 6.5137 - accuracy: 0.0232\n",
            "Epoch 4/100\n",
            "15462/15462 [==============================] - 12s 778us/sample - loss: 6.4807 - accuracy: 0.0224\n",
            "Epoch 5/100\n",
            "15462/15462 [==============================] - 12s 767us/sample - loss: 6.4528 - accuracy: 0.0235\n",
            "Epoch 6/100\n",
            "15462/15462 [==============================] - 12s 773us/sample - loss: 6.4225 - accuracy: 0.0255\n",
            "Epoch 7/100\n",
            "15462/15462 [==============================] - 12s 786us/sample - loss: 6.3963 - accuracy: 0.0255\n",
            "Epoch 8/100\n",
            "15462/15462 [==============================] - 12s 780us/sample - loss: 6.3737 - accuracy: 0.0259\n",
            "Epoch 9/100\n",
            "15462/15462 [==============================] - 12s 785us/sample - loss: 6.3508 - accuracy: 0.0270\n",
            "Epoch 10/100\n",
            "15462/15462 [==============================] - 12s 778us/sample - loss: 6.3276 - accuracy: 0.0259\n",
            "Epoch 11/100\n",
            "15462/15462 [==============================] - 12s 786us/sample - loss: 6.3096 - accuracy: 0.0265\n",
            "Epoch 12/100\n",
            "15462/15462 [==============================] - 12s 786us/sample - loss: 6.2865 - accuracy: 0.0270\n",
            "Epoch 13/100\n",
            "15462/15462 [==============================] - 12s 774us/sample - loss: 6.2694 - accuracy: 0.0286\n",
            "Epoch 14/100\n",
            "15462/15462 [==============================] - 13s 819us/sample - loss: 6.2493 - accuracy: 0.0287\n",
            "Epoch 15/100\n",
            "15462/15462 [==============================] - 12s 779us/sample - loss: 6.2303 - accuracy: 0.0301\n",
            "Epoch 16/100\n",
            "15462/15462 [==============================] - 12s 779us/sample - loss: 6.2133 - accuracy: 0.0295\n",
            "Epoch 17/100\n",
            "15462/15462 [==============================] - 12s 783us/sample - loss: 6.1936 - accuracy: 0.0310\n",
            "Epoch 18/100\n",
            "15462/15462 [==============================] - 12s 775us/sample - loss: 6.1770 - accuracy: 0.0349\n",
            "Epoch 19/100\n",
            "15462/15462 [==============================] - 13s 811us/sample - loss: 6.1581 - accuracy: 0.0352\n",
            "Epoch 20/100\n",
            "15462/15462 [==============================] - 12s 783us/sample - loss: 6.1403 - accuracy: 0.0367\n",
            "Epoch 21/100\n",
            "15462/15462 [==============================] - 12s 783us/sample - loss: 6.1294 - accuracy: 0.0374\n",
            "Epoch 22/100\n",
            "15462/15462 [==============================] - 12s 793us/sample - loss: 6.1082 - accuracy: 0.0385\n",
            "Epoch 23/100\n",
            "15462/15462 [==============================] - 12s 777us/sample - loss: 6.0980 - accuracy: 0.0406\n",
            "Epoch 24/100\n",
            "15462/15462 [==============================] - 12s 785us/sample - loss: 6.0793 - accuracy: 0.0406\n",
            "Epoch 25/100\n",
            "15462/15462 [==============================] - 12s 788us/sample - loss: 6.0654 - accuracy: 0.0405\n",
            "Epoch 26/100\n",
            "15462/15462 [==============================] - 12s 785us/sample - loss: 6.0464 - accuracy: 0.0413\n",
            "Epoch 27/100\n",
            "15462/15462 [==============================] - 12s 788us/sample - loss: 6.0291 - accuracy: 0.0413\n",
            "Epoch 28/100\n",
            "15462/15462 [==============================] - 12s 798us/sample - loss: 6.0130 - accuracy: 0.0434\n",
            "Epoch 29/100\n",
            "15462/15462 [==============================] - 12s 795us/sample - loss: 5.9951 - accuracy: 0.0438\n",
            "Epoch 30/100\n",
            "15462/15462 [==============================] - 12s 791us/sample - loss: 5.9806 - accuracy: 0.0438\n",
            "Epoch 31/100\n",
            "15462/15462 [==============================] - 12s 791us/sample - loss: 5.9684 - accuracy: 0.0438\n",
            "Epoch 32/100\n",
            "15462/15462 [==============================] - 12s 802us/sample - loss: 5.9546 - accuracy: 0.0452\n",
            "Epoch 33/100\n",
            "15462/15462 [==============================] - 12s 799us/sample - loss: 5.9381 - accuracy: 0.0472\n",
            "Epoch 34/100\n",
            "15462/15462 [==============================] - 12s 801us/sample - loss: 5.9219 - accuracy: 0.0465\n",
            "Epoch 35/100\n",
            "15462/15462 [==============================] - 12s 797us/sample - loss: 5.9062 - accuracy: 0.0471\n",
            "Epoch 36/100\n",
            "15462/15462 [==============================] - 12s 795us/sample - loss: 5.8895 - accuracy: 0.0481\n",
            "Epoch 37/100\n",
            "15462/15462 [==============================] - 12s 790us/sample - loss: 5.8789 - accuracy: 0.0491\n",
            "Epoch 38/100\n",
            "15462/15462 [==============================] - 12s 790us/sample - loss: 5.8623 - accuracy: 0.0499\n",
            "Epoch 39/100\n",
            "15462/15462 [==============================] - 13s 832us/sample - loss: 5.8480 - accuracy: 0.0508\n",
            "Epoch 40/100\n",
            "15462/15462 [==============================] - 13s 814us/sample - loss: 5.8311 - accuracy: 0.0501\n",
            "Epoch 41/100\n",
            "15462/15462 [==============================] - 12s 803us/sample - loss: 5.8186 - accuracy: 0.0521\n",
            "Epoch 42/100\n",
            "15462/15462 [==============================] - 12s 805us/sample - loss: 5.8040 - accuracy: 0.0544\n",
            "Epoch 43/100\n",
            "15462/15462 [==============================] - 12s 804us/sample - loss: 5.7875 - accuracy: 0.0539\n",
            "Epoch 44/100\n",
            "15462/15462 [==============================] - 13s 823us/sample - loss: 5.7801 - accuracy: 0.0559\n",
            "Epoch 45/100\n",
            "15462/15462 [==============================] - 13s 809us/sample - loss: 5.7644 - accuracy: 0.0563\n",
            "Epoch 46/100\n",
            "15462/15462 [==============================] - 12s 806us/sample - loss: 5.7514 - accuracy: 0.0561\n",
            "Epoch 47/100\n",
            "15462/15462 [==============================] - 12s 807us/sample - loss: 5.7394 - accuracy: 0.0566\n",
            "Epoch 48/100\n",
            " 2176/15462 [===>..........................] - ETA: 10s - loss: 5.6863 - accuracy: 0.0533"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fXTEO3GJ282",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "loss = history.history['loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
        "plt.title('Training accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
        "plt.title('Training loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Vc6PHgxa6Hm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed_text = \"Help me Obi Wan Kenobi, you're my only hope\"\n",
        "next_words = 100\n",
        "  \n",
        "for _ in range(next_words):\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\tpredicted = model.predict_classes(token_list, verbose=0)\n",
        "\toutput_word = \"\"\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == predicted:\n",
        "\t\t\toutput_word = word\n",
        "\t\t\tbreak\n",
        "\tseed_text += \" \" + output_word\n",
        "print(seed_text)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}